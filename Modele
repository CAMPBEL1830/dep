import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import joblib

# 1. Préparation des Données
# a. Chargement des données
# Remplacez 'your_data.csv' par le chemin de votre fichier de données
data = pd.read_csv('your_data.csv')

# b. Nettoyage des Données
# Remplacez 'target' par le nom de votre colonne cible et les colonnes features par leurs noms respectifs
X = data.drop('target', axis=1)
y = data['target']

# c. Division des Données
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 2. Choix et Entraînement du Modèle
model = LogisticRegression()
model.fit(X_train, y_train)

# 3. Évaluation du Modèle
y_pred = model.predict(X_test)


# a. Métriques d'Évaluation
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1 Score: {f1}")

# b. Matrice de Confusion
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# 4. Amélioration du Modèle (Facultatif)
# a. Hyperparameter Tuning avec GridSearchCV
from sklearn.model_selection import GridSearchCV

param_grid = {'C': [0.1, 1, 10, 100]}
grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)
grid.fit(X_train, y_train)
print(grid.best_params_)

# 5. Déploiement
# a. Sauvegarde du Modèle
joblib.dump(model, 'logistic_regression_model.pkl')

# b. Chargement du Modèle
model = joblib.load('logistic_regression_model.pkl')

# Prédictions sur de nouvelles données
# Remplacez 'new_data.csv' par le chemin de votre nouveau fichier de données
new_data = pd.read_csv('new_data.csv')
predictions = model.predict(new_data)
print(predictions)






code 2

import pandas as pd

# Charger le fichier Excel
file_path = 'C:\\Users\\H10296\\Desktop\\PFEBD ULTIME.xlsx'

# Charger les données à partir du fichier Excel
data = pd.read_excel(file_path)

# Afficher les noms de colonnes pour vérifier leur exactitude
print("Colonnes du DataFrame :", data.columns)

# Vérifier les dimensions du DataFrame
print("Dimensions du DataFrame :", data.shape)

# Vérifier les longueurs des colonnes d'intérêt
columns_of_interest = [
    'Numero dossier enfant', 
    'Montant_encours', 
    'Taux interet',
    'MONTANT NOMINAL_DOSSIER', 
    'COTATION', 
    'ANCIENNETE AVANT PRÊT',
    'solve durée', 
    'Age', 
    'Nombre d\'revenu', 
    'Durée_pret', 
    'MONTANT_NOMINAL_DOSSIER_ANNEE'
]

for col in columns_of_interest:
    if col in data.columns:
        print(f"Longueur de la colonne {col} : {len(data[col])}")
    else:
        print(f"Colonne {col} manquante dans le DataFrame")

# Exemple de manipulation avec vérification des longueurs
# S'assurer que toutes les colonnes d'intérêt existent et ont la même longueur
valid_columns = [col for col in columns_of_interest if col in data.columns]
if len(set(len(data[col]) for col in valid_columns)) == 1:
    # Toutes les colonnes ont la même longueur
    data_of_interest = data[valid_columns]
    print("Les données sont prêtes pour une manipulation supplémentaire")
else:
    print("Certaines colonnes n'ont pas la même longueur, veuillez vérifier vos données")




new code 

# 1. Supprimer les lignes où age = 0, cotation = 0, et taux = 0
data2_cleaned = data2[~((data2['age'] == 0) & (data2['cotation'] == 0) & (data2['taux'] == 0))]

# 2. Remplacer toutes les occurrences de 'X' par 1 dans la colonne cotation
data2_cleaned['cotation'] = data2_cleaned['cotation'].replace('X', 1)

