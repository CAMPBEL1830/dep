import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import joblib

# 1. Préparation des Données
# a. Chargement des données
# Remplacez 'your_data.csv' par le chemin de votre fichier de données
data = pd.read_csv('your_data.csv')

# b. Nettoyage des Données
# Remplacez 'target' par le nom de votre colonne cible et les colonnes features par leurs noms respectifs
X = data.drop('target', axis=1)
y = data['target']

# c. Division des Données
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 2. Choix et Entraînement du Modèle
model = LogisticRegression()
model.fit(X_train, y_train)

# 3. Évaluation du Modèle
y_pred = model.predict(X_test)


# a. Métriques d'Évaluation
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1 Score: {f1}")

# b. Matrice de Confusion
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# 4. Amélioration du Modèle (Facultatif)
# a. Hyperparameter Tuning avec GridSearchCV
from sklearn.model_selection import GridSearchCV

param_grid = {'C': [0.1, 1, 10, 100]}
grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)
grid.fit(X_train, y_train)
print(grid.best_params_)

# 5. Déploiement
# a. Sauvegarde du Modèle
joblib.dump(model, 'logistic_regression_model.pkl')

# b. Chargement du Modèle
model = joblib.load('logistic_regression_model.pkl')

# Prédictions sur de nouvelles données
# Remplacez 'new_data.csv' par le chemin de votre nouveau fichier de données
new_data = pd.read_csv('new_data.csv')
predictions = model.predict(new_data)
print(predictions)






code 2

import pandas as pd

# Charger le fichier Excel
file_path = 'C:\\Users\\H10296\\Desktop\\PFEBD ULTIME.xlsx'

# Charger les données à partir du fichier Excel
data = pd.read_excel(file_path)

# Afficher les noms de colonnes pour vérifier leur exactitude
print("Colonnes du DataFrame :", data.columns)

# Vérifier les dimensions du DataFrame
print("Dimensions du DataFrame :", data.shape)

# Vérifier les longueurs des colonnes d'intérêt
columns_of_interest = [
    'Numero dossier enfant', 
    'Montant_encours', 
    'Taux interet',
    'MONTANT NOMINAL_DOSSIER', 
    'COTATION', 
    'ANCIENNETE AVANT PRÊT',
    'solve durée', 
    'Age', 
    'Nombre d\'revenu', 
    'Durée_pret', 
    'MONTANT_NOMINAL_DOSSIER_ANNEE'
]

for col in columns_of_interest:
    if col in data.columns:
        print(f"Longueur de la colonne {col} : {len(data[col])}")
    else:
        print(f"Colonne {col} manquante dans le DataFrame")

# Exemple de manipulation avec vérification des longueurs
# S'assurer que toutes les colonnes d'intérêt existent et ont la même longueur
valid_columns = [col for col in columns_of_interest if col in data.columns]
if len(set(len(data[col]) for col in valid_columns)) == 1:
    # Toutes les colonnes ont la même longueur
    data_of_interest = data[valid_columns]
    print("Les données sont prêtes pour une manipulation supplémentaire")
else:
    print("Certaines colonnes n'ont pas la même longueur, veuillez vérifier vos données")




new code 

# 1. Supprimer les lignes où age = 0, cotation = 0, et taux = 0
data2_cleaned = data2[~((data2['age'] == 0) & (data2['cotation'] == 0) & (data2['taux'] == 0))]

# 2. Remplacer toutes les occurrences de 'X' par 1 dans la colonne cotation
data2_cleaned['cotation'] = data2_cleaned['cotation'].replace('X', 1)



bossssssssssssssssssssssssssssssssssss


 2. Créer une instance du modèle de régression logistique
logistic_regression_model = LogisticRegression()

# 3. Entraîner le modèle sur les données d'entraînement
logistic_regression_model.fit(X_train, y_train)

# 4. Faire des prédictions sur les données de test
y_pred = logistic_regression_model.predict(X_test)

# 5. Évaluer les performances du modèle
# Calculer l'accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Matrice de confusion
conf_matrix = confusion_matrix(y_test, y_pred)
print("Matrice de confusion:\n", conf_matrix)

# Rapport de classification
class_report = classification_report(y_test, y_pred)
print("Rapport de classification:\n", class_report)




data3['COTATION'] = data3['COTATION'].str.replace(r'[+-]', '', regex=True)






graphhhhhh

# Compter le nombre d'éléments uniques dans la colonne
value_counts = data['COTATION'].value_counts()

# Créer le graphique de répartition
plt.figure(figsize=(10, 6))
sns.barplot(x=value_counts.index, y=value_counts.values, palette='viridis')


# Ajouter des annotations pour chaque barre
for p in bar_plot.patches:
    bar_plot.annotate(format(p.get_height(), '.0f'), 
                      (p.get_x() + p.get_width() / 2., p.get_height()), 
                      ha = 'center', va = 'center', 
                      xytext = (0, 9), 
                      textcoords = 'offset points')
plt.title('Répartition du nombre d\'éléments uniques dans la colonne COTATION')
plt.xlabel('Valeurs uniques')
plt.ylabel('Nombre d\'occurrences')
plt.xticks(rotation=45)
plt.show()









amelioration 

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression

# Définir les paramètres à tester
param_grid = {
    'C': [0.01, 0.1, 1, 10, 100],  # Valeurs de régularisation
    'penalty': ['l1', 'l2'],        # Type de régularisation
}

# Création du modèle
logistic_regression_model = LogisticRegression(solver='liblinear')  # Utiliser 'liblinear' pour la régularisation l1

# Recherche des meilleurs paramètres
grid_search = GridSearchCV(logistic_regression_model, param_grid, cv=5)
grid_search.fit(X_train, y_train)

# Meilleur modèle et ses paramètres
print("Meilleurs paramètres:", grid_search.best_params_)




evaluation 



from sklearn.metrics import roc_curve, auc

# Prédictions de probabilité
y_prob = logistic_regression_model.predict_proba(X_test)[:, 1]

# Calcul de la courbe ROC
fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc='lower right')
plt.show()



echantionnage 



from imblearn.over_sampling import SMOTE

# Création de l'objet SMOTE
smote = SMOTE()

# Rééchantillonnage des données d'entraînement
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)






arbre de decision 

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt

# Charger vos données
# data2 = pd.read_csv('votre_fichier.csv')  # Exemple pour charger les données depuis un fichier CSV

# Préparer les données
X = data2.drop(columns=['target'])
y = data2['target']

# Diviser les données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Créer et entraîner le modèle d'arbre de décision
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)

# Faire des prédictions
y_pred = model.predict(X_test)

# Évaluer la précision du modèle
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

# Afficher un rapport de classification
print(classification_report(y_test, y_pred))

# Visualiser l'arbre de décision
plt.figure(figsize=(20,10))
plot_tree(model, filled=True, feature_names=X.columns, class_names=['class_0', 'class_1'])
plt.show()







nouvelle oportunite 
import pandas as pd
from sklearn.model_selection import train_test_split

# Création de DataFrames d'exemple
data = pd.DataFrame({
    'A': ['cat', 'dog', 'cat', 'dog', 'bird'],
    'B': [1, 2, 3, 4, 5],
    'target': [0, 1, 0, 1, 0]
})

# Séparation des données en ensembles d'entraînement et de test
X = data.drop('target', axis=1)
y = data['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Concaténer les ensembles d'entraînement et de test
X_combined = pd.concat([X_train, X_test], keys=['train', 'test'])

# Encodage one-hot des variables catégorielles
X_combined_encoded = pd.get_dummies(X_combined)

# Séparation des ensembles d'entraînement et de test après encodage
X_train_encoded = X_combined_encoded.xs('train')
X_test_encoded = X_combined_encoded.xs('test')

# Vérification des résultats
print("Training DataFrame after encoding:")
print(X_train_encoded)
print("\nTesting DataFrame after encoding:")
print(X_test_encoded)

