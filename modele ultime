import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import log_loss, accuracy_score, precision_score, recall_score, f1_score

# Charger les données
data4 = pd.read_csv('chemin/vers/data4.csv')

# Séparer les caractéristiques (features) et la cible (target)
X = data4.drop('target', axis=1)  # Assurez-vous de remplacer 'target' par le nom de votre colonne cible
y = data4['target']  # Assurez-vous de remplacer 'target' par le nom de votre colonne cible

# Séparer les colonnes numériques et catégorielles
numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns
categorical_cols = X.select_dtypes(include=['object']).columns

# Préparer les préprocesseurs pour les colonnes numériques et catégorielles
numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown='ignore')

# Créer le transformateur en colonne
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# Créer le pipeline avec le préprocesseur et le modèle de régression logistique
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter=1000))
])

# Diviser les données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entraîner le modèle
model.fit(X_train, y_train)

# Prédire sur l'ensemble de test
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)

# Calculer les métriques
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')
logloss = log_loss(y_test, y_pred_proba)

# Afficher les résultats
print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')
print(f'Log Loss: {logloss:.4f}')

# Effectuer une validation croisée pour évaluer le surapprentissage
cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_log_loss')
print(f'Cross-Validated Log Loss: {-cv_scores.mean():.4f}')






import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import log_loss, accuracy_score, precision_score, recall_score, f1_score

# Charger les données
data4 = pd.read_csv('chemin/vers/data4.csv')

# Séparer les caractéristiques (features) et la cible (target)
X = data4.drop('target', axis=1)  # Assurez-vous de remplacer 'target' par le nom de votre colonne cible
y = data4['target']  # Assurez-vous de remplacer 'target' par le nom de votre colonne cible

# Séparer les colonnes numériques et catégorielles
numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns
categorical_cols = X.select_dtypes(include=['object', 'int64', 'float64']).columns.difference(numerical_cols)

# Convertir toutes les colonnes catégorielles en chaînes de caractères
X[categorical_cols] = X[categorical_cols].astype(str)

# Préparer les préprocesseurs pour les colonnes numériques et catégorielles
numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown='ignore')

# Créer le transformateur en colonne
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# Créer le pipeline avec le préprocesseur et le modèle de régression logistique
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter=1000))
])

# Diviser les données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entraîner le modèle
model.fit(X_train, y_train)

# Prédire sur l'ensemble de test
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)

# Calculer les métriques
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')
logloss = log_loss(y_test, y_pred_proba)

# Afficher les résultats
print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')
print(f'Log Loss: {logloss:.4f}')

# Effectuer une validation croisée pour évaluer le surapprentissage
cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_log_loss')
print(f'Cross-Validated Log Loss: {-cv_scores.mean():.4f}')




import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import log_loss, accuracy_score, precision_score, recall_score, f1_score

# Charger les données
data4 = pd.read_csv('chemin/vers/data4.csv')

# Séparer les caractéristiques (features) et la cible (target)
X = data4.drop('target', axis=1)  # Assurez-vous de remplacer 'target' par le nom de votre colonne cible
y = data4['target']  # Assurez-vous de remplacer 'target' par le nom de votre colonne cible

# Séparer les colonnes numériques et catégorielles
numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns
categorical_cols = X.select_dtypes(include=['object']).columns

# Convertir toutes les colonnes catégorielles en chaînes de caractères
X[categorical_cols] = X[categorical_cols].astype(str)

# Préparer les préprocesseurs pour les colonnes numériques et catégorielles
numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown='ignore')

# Créer le transformateur en colonne
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# Créer le pipeline avec le préprocesseur et le modèle de régression logistique
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter=1000))
])

# Diviser les données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entraîner le modèle
model.fit(X_train, y_train)

# Prédire sur l'ensemble de test
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)

# Calculer les métriques
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')
logloss = log_loss(y_test, y_pred_proba)

# Afficher les résultats
print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')
print(f'Log Loss: {logloss:.4f}')

# Effectuer une validation croisée pour évaluer le surapprentissage
cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_log_loss')
print(f'Cross-Validated Log Loss: {-cv_scores.mean():.4f}')




import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Charger les données
data5 = pd.read_csv('chemin/vers/data5.csv')

# Séparer les caractéristiques (features) et la cible (target)
X = data5.drop('target', axis=1)  # Assurez-vous de remplacer 'target' par le nom de votre colonne cible
y = data5['target']  # Assurez-vous de remplacer 'target' par le nom de votre colonne cible

# Séparer les colonnes numériques et catégorielles
numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns
categorical_cols = X.select_dtypes(include=['object']).columns

# Convertir toutes les colonnes catégorielles en chaînes de caractères
X[categorical_cols] = X[categorical_cols].astype(str)

# Préparer les préprocesseurs pour les colonnes numériques et catégorielles
numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown='ignore')

# Créer le transformateur en colonne
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# Créer le pipeline avec le préprocesseur et le modèle SVM
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', SVC(probability=True))
])

# Diviser les données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entraîner le modèle
model.fit(X_train, y_train)

# Prédire sur l'ensemble de test
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)

# Calculer les métriques
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

# Afficher les résultats
print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

# Effectuer une validation croisée pour évaluer le surapprentissage
cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
print(f'Cross-Validated Accuracy: {cv_scores.mean():.4f}')






import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss

# Charger les données
data5 = pd.read_csv('chemin/vers/data5.csv')

# Séparer les caractéristiques (features) et la cible (target)
X = data5.drop('target', axis=1)  # Assurez-vous de remplacer 'target' par le nom de votre colonne cible
y = data5['target']  # Assurez-vous de remplacer 'target' par le nom de votre colonne cible

# Séparer les colonnes numériques et catégorielles
numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns
categorical_cols = X.select_dtypes(include=['object']).columns

# Convertir toutes les colonnes catégorielles en chaînes de caractères
X[categorical_cols] = X[categorical_cols].astype(str)

# Préparer les préprocesseurs pour les colonnes numériques et catégorielles
numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown='ignore')

# Créer le transformateur en colonne
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# Créer le pipeline avec le préprocesseur et le modèle de Random Forest
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])

# Diviser les données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entraîner le modèle
model.fit(X_train, y_train)

# Prédire sur l'ensemble de test
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)

# Calculer les métriques
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')
logloss = log_loss(y_test, y_pred_proba)

# Afficher les résultats
print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')
print(f'Log Loss: {logloss:.4f}')

# Effectuer une validation croisée pour évaluer le surapprentissage
cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
print(f'Cross-Validated Accuracy: {cv_scores.mean():.4f}')




import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss

# Charger les données
data5 = pd.read_csv('chemin/vers/data5.csv')

# Séparer les caractéristiques (features) et la cible (target)
X = data5.drop('target', axis=1)  # Assurez-vous de remplacer 'target' par le nom de votre colonne cible
y = data5['target']  # Assurez-vous de remplacer 'target' par le nom de votre colonne cible

# Séparer les colonnes numériques et catégorielles
numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns
categorical_cols = X.select_dtypes(include=['object']).columns

# Convertir toutes les colonnes catégorielles en chaînes de caractères
X[categorical_cols] = X[categorical_cols].astype(str)

# Préparer les préprocesseurs pour les colonnes numériques et catégorielles
numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown='ignore')

# Créer le transformateur en colonne
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# Créer le pipeline avec le préprocesseur et le modèle de Random Forest
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])

# Définir les hyperparamètres à tester
param_grid = {
    'classifier__n_estimators': [100, 200],
    'classifier__max_depth': [10, 20, None],
    'classifier__min_samples_split': [2, 5, 10],
    'classifier__min_samples_leaf': [1, 2, 4],
    'classifier__bootstrap': [True, False]
}

# Utiliser GridSearchCV pour trouver les meilleurs hyperparamètres
grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)

# Diviser les données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entraîner le modèle avec les meilleurs hyperparamètres trouvés
grid_search.fit(X_train, y_train)

# Meilleurs hyperparamètres
print(f'Best parameters found: {grid_search.best_params_}')

# Prédire sur l'ensemble de test avec le meilleur modèle
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)
y_pred_proba = best_model.predict_proba(X_test)

# Calculer les métriques
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')
logloss = log_loss(y_test, y_pred_proba)

# Afficher les résultats
print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')
print(f'Log Loss: {logloss:.4f}')

# Effectuer une validation croisée pour évaluer le surapprentissage
cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='accuracy')
print(f'Cross-Validated Accuracy: {cv_scores.mean():.4f}')








import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, log_loss
from sklearn.preprocessing import LabelEncoder

# Exemple de DataFrame
data5 = pd.DataFrame({
    'revenu': [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000],
    'age': [25, 45, 35, 50, 23, 34, 65, 45, 25, 30],
    'groupe': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B', 'A', 'C'],
    'cible': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]
})

# Séparation des features et de la cible
X = data5.drop(columns=['cible'])
y = data5['cible']

# Encodage des variables catégorielles
le = LabelEncoder()
for col in X.select_dtypes(include=['object']).columns:
    X[col] = le.fit_transform(X[col])

# Séparation des données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Définition du modèle et des hyperparamètres à rechercher
rf = RandomForestClassifier(random_state=42)
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

# Recherche des meilleurs hyperparamètres
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='neg_log_loss', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Meilleur modèle
best_rf = grid_search.best_estimator_

# Prédictions
y_pred = best_rf.predict(X_test)
y_pred_proba = best_rf.predict_proba(X_test)

# Calcul des métriques
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)
log_loss_value = log_loss(y_test, y_pred_proba)

# Affichage des résultats
print("Meilleurs hyperparamètres : ", grid_search.best_params_)
print("Matrice de confusion :\n", conf_matrix)
print("Rapport de classification :\n", class_report)
print("Log Loss : ", log_loss_value)












import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, log_loss
from sklearn.preprocessing import LabelEncoder

# Exemple de DataFrame
data5 = pd.DataFrame({
    'revenu': [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000],
    'age': [25, 45, 35, 50, 23, 34, 65, 45, 25, 30],
    'groupe': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B', 'A', 'C'],
    'cible': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]
})

# Séparation des features et de la cible
X = data5.drop(columns=['cible'])
y = data5['cible']

# Vérification des types de données et conversion si nécessaire
for col in X.columns:
    if X[col].dtype == 'object':
        X[col] = X[col].astype(str)

# Encodage des variables catégorielles
le = LabelEncoder()
for col in X.select_dtypes(include=['object']).columns:
    X[col] = le.fit_transform(X[col])

# Séparation des données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Définition du modèle et des hyperparamètres à rechercher
rf = RandomForestClassifier(random_state=42)
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

# Recherche des meilleurs hyperparamètres
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='neg_log_loss', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Meilleur modèle
best_rf = grid_search.best_estimator_

# Prédictions
y_pred = best_rf.predict(X_test)
y_pred_proba = best_rf.predict_proba(X_test)

# Calcul des métriques
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)
log_loss_value = log_loss(y_test, y_pred_proba)

# Affichage des résultats
print("Meilleurs hyperparamètres : ", grid_search.best_params_)
print("Matrice de confusion :\n", conf_matrix)
print("Rapport de classification :\n", class_report)
print("Log Loss : ", log_loss_value)







import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, log_loss
from sklearn.preprocessing import LabelEncoder

# Exemple de DataFrame
data5 = pd.DataFrame({
    'revenu': [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000],
    'age': [25, 45, 35, 50, 23, 34, 65, 45, 25, 30],
    'groupe': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B', 'A', 'C'],
    'cible': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]
})

# Vérification des types de données et conversion si nécessaire
for col in data5.columns:
    if data5[col].dtype == 'object':
        data5[col] = data5[col].astype(str)

# Gestion des valeurs manquantes
data5 = data5.dropna(subset=['revenu'])  # Suppression des lignes où 'revenu' est manquant
data5['revenu'] = pd.to_numeric(data5['revenu'], errors='coerce')  # Conversion de 'revenu' en numérique
data5 = data5.dropna(subset=['revenu'])  # Suppression des lignes où 'revenu' ne peut pas être converti en numérique

# Séparation des features et de la cible
X = data5.drop(columns=['cible'])
y = data5['cible']

# Encodage des variables catégorielles
le = LabelEncoder()
for col in X.select_dtypes(include=['object']).columns:
    X[col] = le.fit_transform(X[col])

# Séparation des données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Définition du modèle et des hyperparamètres à rechercher
rf = RandomForestClassifier(random_state=42)
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

# Recherche des meilleurs hyperparamètres
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='neg_log_loss', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Meilleur modèle
best_rf = grid_search.best_estimator_

# Prédictions
y_pred = best_rf.predict(X_test)
y_pred_proba = best_rf.predict_proba(X_test)

# Calcul des métriques
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)
log_loss_value = log_loss(y_test, y_pred_proba)

# Affichage des résultats
print("Meilleurs hyperparamètres : ", grid_search.best_params_)
print("Matrice de confusion :\n", conf_matrix)
print("Rapport de classification :\n", class_report)
print("Log Loss : ", log_loss_value)












import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, log_loss

# Étape 1 : Préparation des données
# Remplacez 'target_column' par le nom de votre colonne cible
X = data5.drop('target_column', axis=1)  # Variables explicatives
y = data5['target_column']  # Variable cible

# Étape 2 : Séparation des données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Étape 3 : Entraînement du modèle Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
rf_model.fit(X_train, y_train)

# Étape 4 : Évaluation initiale du modèle
y_pred = rf_model.predict(X_test)
y_pred_proba = rf_model.predict_proba(X_test)

print("Évaluation Initiale du Modèle:")
print(classification_report(y_test, y_pred))
print("Matrice de Confusion:")
print(confusion_matrix(y_test, y_pred))
print(f'Log Loss: {log_loss(y_test, y_pred_proba)}')

# Étape 5 : Validation croisée et réglage des hyperparamètres
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_log_loss', n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)

best_model = grid_search.best_estimator_

# Étape 6 : Réévaluation du modèle optimal
y_pred_optimal = best_model.predict(X_test)
y_pred_proba_optimal = best_model.predict_proba(X_test)

print("Évaluation du Modèle Optimal:")
print(classification_report(y_test, y_pred_optimal))
print("Matrice de Confusion (Modèle Optimal):")
print(confusion_matrix(y_test, y_pred_optimal))
print(f'Log Loss Optimal: {log_loss(y_test, y_pred_proba_optimal)}')

# Étape 7 : Vérification de l'overfitting
train_pred_optimal = best_model.predict(X_train)
train_pred_proba_optimal = best_model.predict_proba(X_train)

print("Évaluation sur Ensemble d'Entraînement (pour vérifier l'overfitting):")
print(classification_report(y_train, train_pred_optimal))
print(f'Log Loss Entraînement: {log_loss(y_train, train_pred_proba_optimal)}')












import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, log_loss
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Étape 1 : Préparation des données
# Remplacez 'target_column' par le nom de votre colonne cible
target_column = 'your_target_column'  # Changez cela avec le nom de votre colonne cible
X = data5.drop(target_column, axis=1)  # Variables explicatives
y = data5[target_column]  # Variable cible

# Identifier les colonnes numériques et catégorielles
num_cols = X.select_dtypes(include=['int64', 'float64']).columns
cat_cols = X.select_dtypes(include=['object', 'category']).columns

# Étape 2 : Séparation des données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Pipeline pour prétraiter les données
preprocessor = ColumnTransformer(
    transformers=[
        ('num', 'passthrough', num_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
    ])

# Étape 3 : Entraînement du modèle Random Forest avec pipeline
rf_model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'))
])

rf_model.fit(X_train, y_train)

# Étape 4 : Évaluation initiale du modèle
y_pred = rf_model.predict(X_test)
y_pred_proba = rf_model.predict_proba(X_test)

print("Évaluation Initiale du Modèle:")
print(classification_report(y_test, y_pred))
print("Matrice de Confusion:")
print(confusion_matrix(y_test, y_pred))
print(f'Log Loss: {log_loss(y_test, y_pred_proba)}')

# Étape 5 : Validation croisée et réglage des hyperparamètres
param_grid = {
    'classifier__n_estimators': [100, 200, 300],
    'classifier__max_depth': [None, 10, 20, 30],
    'classifier__min_samples_split': [2, 5, 10],
    'classifier__min_samples_leaf': [1, 2, 4],
    'classifier__bootstrap': [True, False]
}

grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_log_loss', n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)

best_model = grid_search.best_estimator_

# Étape 6 : Réévaluation du modèle optimal
y_pred_optimal = best_model.predict(X_test)
y_pred_proba_optimal = best_model.predict_proba(X_test)

print("Évaluation du Modèle Optimal:")
print(classification_report(y_test, y_pred_optimal))
print("Matrice de Confusion (Modèle Optimal):")
print(confusion_matrix(y_test, y_pred_optimal))
print(f'Log Loss Optimal: {log_loss(y_test, y_pred_proba_optimal)}')

# Étape 7 : Vérification de l'overfitting
train_pred_optimal = best_model.predict(X_train)
train_pred_proba_optimal = best_model.predict_proba(X_train)

print("Évaluation sur Ensemble d'Entraînement (pour vérifier l'overfitting):")
print(classification_report(y_train, train_pred_optimal))
print(f'Log Loss Entraînement: {log_loss(y_train, train_pred_proba_optimal)}')













import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, log_loss
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

# Étape 1 : Préparation des données
target_column = 'your_target_column'  # Changez cela avec le nom de votre colonne cible
X = data5.drop(target_column, axis=1)  # Variables explicatives
y = data5[target_column]  # Variable cible

# Identifier les colonnes numériques et catégorielles
num_cols = X.select_dtypes(include=['int64', 'float64']).columns
cat_cols = X.select_dtypes(include=['object', 'category']).columns

# Étape 2 : Uniformiser les colonnes
# Convertir les colonnes mixtes en chaînes de caractères
for col in cat_cols:
    X[col] = X[col].astype(str)

# Séparation des données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Pipeline pour prétraiter les données
preprocessor = ColumnTransformer(
    transformers=[
        ('num', SimpleImputer(strategy='median'), num_cols),  # Imputation des valeurs manquantes
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
    ])

# Étape 3 : Entraînement du modèle Random Forest avec pipeline
rf_model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'))
])

rf_model.fit(X_train, y_train)

# Étape 4 : Évaluation initiale du modèle
y_pred = rf_model.predict(X_test)
y_pred_proba = rf_model.predict_proba(X_test)

print("Évaluation Initiale du Modèle:")
print(classification_report(y_test, y_pred))
print("Matrice de Confusion:")
print(confusion_matrix(y_test, y_pred))
print(f'Log Loss: {log_loss(y_test, y_pred_proba)}')

# Étape 5 : Validation croisée et réglage des hyperparamètres
param_grid = {
    'classifier__n_estimators': [100, 200, 300],
    'classifier__max_depth': [None, 10, 20, 30],
    'classifier__min_samples_split': [2, 5, 10],
    'classifier__min_samples_leaf': [1, 2, 4],
    'classifier__bootstrap': [True, False]
}

grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_log_loss', n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)

best_model = grid_search.best_estimator_

# Étape 6 : Réévaluation du modèle optimal
y_pred_optimal = best_model.predict(X_test)
y_pred_proba_optimal = best_model.predict_proba(X_test)

print("Évaluation du Modèle Optimal:")
print(classification_report(y_test, y_pred_optimal))
print("Matrice de Confusion (Modèle Optimal):")
print(confusion_matrix(y_test, y_pred_optimal))
print(f'Log Loss Optimal: {log_loss(y_test, y_pred_proba_optimal)}')

# Étape 7 : Vérification de l'overfitting
train_pred_optimal = best_model.predict(X_train)
train_pred_proba_optimal = best_model.predict_proba(X_train)

print("Évaluation sur Ensemble d'Entraînement (pour vérifier l'overfitting):")
print(classification_report(y_train, train_pred_optimal))
print(f'Log Loss Entraînement: {log_loss(y_train, train_pred_proba_optimal)}')








import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, log_loss
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

# Étape 1 : Préparation des données
target_column = 'your_target_column'  # Changez cela avec le nom de votre colonne cible
X = data5.drop(target_column, axis=1)  # Variables explicatives
y = data5[target_column]  # Variable cible

# Identifier les colonnes numériques et catégorielles
num_cols = X.select_dtypes(include=['int64', 'float64']).columns
cat_cols = X.select_dtypes(include=['object', 'category']).columns

# Étape 2 : Uniformiser les colonnes
# Convertir les colonnes mixtes en chaînes de caractères
for col in cat_cols:
    X[col] = X[col].astype(str)

# Séparation des données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Pipeline pour prétraiter les données
preprocessor = ColumnTransformer(
    transformers=[
        ('num', SimpleImputer(strategy='median'), num_cols),  # Imputation des valeurs manquantes
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
    ])

# Étape 3 : Entraînement du modèle Random Forest avec pipeline
rf_model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'))
])

# Validation croisée
cross_val_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='neg_log_loss')
print(f'Validation Croisée Log Loss Moyenne: {-cross_val_scores.mean()}')

# Entraînement du modèle sur l'ensemble d'entraînement complet
rf_model.fit(X_train, y_train)

# Étape 4 : Évaluation initiale du modèle
# Sur l'ensemble de test
y_pred_test = rf_model.predict(X_test)
y_pred_proba_test = rf_model.predict_proba(X_test)

print("Évaluation sur Ensemble de Test:")
print(classification_report(y_test, y_pred_test))
print("Matrice de Confusion sur Test:")
print(confusion_matrix(y_test, y_pred_test))
print(f'Log Loss sur Test: {log_loss(y_test, y_pred_proba_test)}')

# Sur l'ensemble d'entraînement
y_pred_train = rf_model.predict(X_train)
y_pred_proba_train = rf_model.predict_proba(X_train)

print("Évaluation sur Ensemble d'Entraînement:")
print(classification_report(y_train, y_pred_train))
print("Matrice de Confusion sur Entraînement:")
print(confusion_matrix(y_train, y_pred_train))
print(f'Log Loss sur Entraînement: {log_loss(y_train, y_pred_proba_train)}')

# Étape 5 : Validation croisée et réglage des hyperparamètres
param_grid = {
    'classifier__n_estimators': [100, 200, 300],
    'classifier__max_depth': [None, 10, 20, 30],
    'classifier__min_samples_split': [2, 5, 10],
    'classifier__min_samples_leaf': [1, 2, 4],
    'classifier__bootstrap': [True, False]
}

grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_log_loss', n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)

best_model = grid_search.best_estimator_

# Étape 6 : Réévaluation du modèle optimal
y_pred_optimal = best_model.predict(X_test)
y_pred_proba_optimal = best_model.predict_proba(X_test)

print("Évaluation du Modèle Optimal sur Ensemble de Test:")
print(classification_report(y_test, y_pred_optimal))
print("Matrice de Confusion (Modèle Optimal sur Test):")
print(confusion_matrix(y_test, y_pred_optimal))
print(f'Log Loss Optimal sur Test: {log_loss(y_test, y_pred_proba_optimal)}')

# Sur l'ensemble d'entraînement pour le modèle optimal
train_pred_optimal = best_model.predict(X_train)
train_pred_proba_optimal = best_model.predict_proba(X_train)

print("Évaluation du Modèle Optimal sur Ensemble d'Entraînement:")
print(classification_report(y_train, train_pred_optimal))
print(f'Log Loss Optimal sur Entraînement: {log_loss(y_train, train_pred_proba_optimal)}')

